#!/usr/bin/env python3
"""
Mesh generation and loading utilities for 3D thermal analysis
"""

import os
import sys
import time
from mpi4py import MPI
import numpy as np
import gc
from dolfinx.geometry import bb_tree, compute_collisions_points, compute_colliding_cells


sys.path.append("/home/jambaman10/research/test5/")
from solver.utils import mpi_print
from solver.config import *

# Add path for gri module imports
script_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(script_dir)
if parent_dir not in sys.path:
    sys.path.insert(0, parent_dir)

# Import mesh generator
try:
    from solver.mesher import mesh_polygon
    from geometry.__archive.geometry import Polygon
    from geometry.shape_generators import generate_rectangle
    MESH_GEN_AVAILABLE = True
    mpi_print("✅ Successfully imported mesh generation module")
except ImportError as e:
    mpi_print(f"❌ Warning: Could not import mesh generation module: {e}")
    MESH_GEN_AVAILABLE = False

def get_mesh_statistics_from_gmsh(mesh_file_path):
    """Get comprehensive mesh statistics from GMSH file"""
    if not os.path.exists(mesh_file_path):
        raise FileNotFoundError(f"Mesh file not found: {mesh_file_path}")
    
    try:
        import gmsh
        
        # Initialize GMSH
        gmsh.initialize()
        
        # Open the mesh file
        gmsh.open(mesh_file_path)
        
        # Get mesh statistics
        nodes = gmsh.model.mesh.getNodes()
        elements = gmsh.model.mesh.getElements()
        
        # Extract statistics
        num_nodes = len(nodes[0]) if len(nodes) > 0 else 0
        num_elements = sum(len(elem_tags) for elem_tags in elements[1]) if len(elements) > 1 else 0
        
        # Get element types and counts
        element_types = {}
        for i, elem_type in enumerate(elements[0]):
            if len(elements) > 1 and i < len(elements[1]):
                element_types[str(elem_type)] = len(elements[1][i])  # Convert to string for JSON compatibility
        
        # Get physical groups
        physical_groups = gmsh.model.getPhysicalGroups()
        num_physical_groups = len(physical_groups)
        
        # Get mesh dimension
        mesh_dim = gmsh.model.getDimension()
        
        # Calculate mesh quality metrics if available
        mesh_stats = {
            "mesh_dimension": mesh_dim,
            "total_nodes": num_nodes,
            "total_elements": num_elements,
            "element_types": element_types,
            "num_physical_groups": num_physical_groups,
            "mesh_file": mesh_file_path
        }
        
        # Add element type breakdown (keys are already strings)
        for elem_type, count in element_types.items():
            mesh_stats[f"elements_type_{elem_type}"] = count
        
        mpi_print(f"GMSH mesh statistics: {num_nodes} nodes, {num_elements} elements")
        
        return mesh_stats
        
    except ImportError:
        mpi_print("GMSH not available. Please install with: pip install gmsh")
        raise
    except Exception as e:
        mpi_print(f"Error reading GMSH mesh statistics: {e}")
        raise
    finally:
        try:
            gmsh.finalize()
        except:
            pass

def get_mesh_statistics(domain_or_file, V=None):
    """Get comprehensive mesh statistics from either DOLFINx domain or GMSH file"""
    
    # Check if input is a file path (string)
    if isinstance(domain_or_file, str):
        return get_mesh_statistics_from_gmsh(domain_or_file)
    
    # Otherwise, assume it's a DOLFINx domain object
    domain = domain_or_file
    
    # Get mesh topology info
    mesh_topology = domain.topology
    num_cells = mesh_topology.index_map(mesh_topology.dim).size_global
    num_vertices = mesh_topology.index_map(0).size_global
    
    # Get function space info if provided
    total_dofs = 0
    local_dofs = 0
    if V is not None:
        total_dofs = V.dofmap.index_map.size_global
        local_dofs = V.dofmap.index_map.size_local
    
    # Get mesh geometry info
    mesh_dim = mesh_topology.dim
    cell_type = mesh_topology.cell_type
    
    # Calculate mesh quality metrics if available
    mesh_stats = {
        "mesh_dimension": mesh_dim,
        "cell_type": str(cell_type),
        "total_cells": num_cells,
        "total_vertices": num_vertices,
        "total_dofs": total_dofs,
        "local_dofs_per_process": local_dofs,
        "dofs_per_cell": total_dofs / num_cells if num_cells > 0 else 0
    }
    
    return mesh_stats

def load_mesh_from_file(mesh_file_path):
    """Load mesh from file generated by gen_mesh.py with MPI-safe reading"""
    if not os.path.exists(mesh_file_path):
        raise FileNotFoundError(f"Mesh file not found: {mesh_file_path}")
    
    mpi_print(f"Loading mesh from: {mesh_file_path}")
    
    # Wait for file to be fully written
    time.sleep(0.1)
    MPI.COMM_WORLD.barrier()
    
    try:
        from dolfinx.io import gmshio
        
        # Use simpler mesh loading without partitioner specification
        domain, cell_markers, facet_markers = gmshio.read_from_msh(
            mesh_file_path, MPI.COMM_WORLD, gdim=3
        )
        
        mpi_print(f"Mesh loaded successfully with {domain.topology.index_map(3).size_global} cells")
        return domain, cell_markers, facet_markers
    
    except ImportError:
        mpi_print("gmshio not available. Please install with appropriate DOLFINx version.")
        raise
    except Exception as e:
        mpi_print(f"Error loading mesh: {e}")
        mpi_print(f"Mesh file: {mesh_file_path}")
        mpi_print("This might be due to mesh format issues or file corruption.")
        
        # Try to get more info about the file
        if os.path.exists(mesh_file_path):
            file_size = os.path.getsize(mesh_file_path)
            mpi_print(f"Mesh file size: {file_size} bytes")
        
        raise

def eval_points(mesh, points, u, z_coordinate=None, precomputed_data=None):
    """
    Evaluate a function at points in the mesh.
    Args:
        mesh: DOLFINx mesh
        points: Array of points [(x, y), ...] or [(x, y, z), ...] where to evaluate the function
        u: DOLFINx Function containing the function to evaluate
        z_coordinate: If provided, will be used as the z-coordinate for all points when points are 2D
                     (useful for toolpath evaluation at a specific height)
        precomputed_data: Optional tuple of (points_on_proc, cells_on_proc, point_indices) from precompute_eval_points_data
        
    Returns:
        Array of function values at the specified points
    """
    
    if precomputed_data is None:
        # Ensure points is a proper numpy array with correct shape
        points = np.array(points, dtype=np.float64)
        if points.ndim == 1:
            points = points.reshape(1, -1)
            
        # Handle 2D points by adding z-coordinate
        if points.shape[1] == 2:
            if z_coordinate is None:
                z_coordinate = BASEPLATE_THICKNESS+PART_HEIGHT-1e-6
                print(f"Warning: No z_coordinate provided for 2D points, using z={z_coordinate} as defined in config.py")
            
            # Create a new array with z-coordinate added
            points_3d = np.zeros((points.shape[0], 3), dtype=np.float64)
            points_3d[:, 0] = points[:, 0]  # x-coordinates
            points_3d[:, 1] = points[:, 1]  # y-coordinates
            points_3d[:, 2] = z_coordinate  # z-coordinate (same for all points)
            points = points_3d
        
        # Create bounding box tree - DOLFINx 0.9.0 syntax using bb_tree function
        bb_tree_obj = bb_tree(mesh, mesh.topology.dim)
        
        # Find candidate cells for each point
        # DOLFINx 0.9.0 expects points in shape (num_points, 3)
        potential_cells = compute_collisions_points(bb_tree_obj, points)
        
        # Find which cell actually contains each point
        cells = compute_colliding_cells(mesh, potential_cells, points)

        # Filter out points not found in the mesh
        points_on_proc = []
        cells_on_proc = []
        point_indices = []  # Track original indices
        
        for i in range(len(points)):
            cell_links = cells.links(i)
            if len(cell_links) > 0:
                points_on_proc.append(points[i])
                cells_on_proc.append(cell_links[0])  # Take the first containing cell
                point_indices.append(i)  # Store original index

        if len(points_on_proc) == 0:
            # No points found on this process - return an array of empty arrays
            # This ensures consistent return structure for MPI communication
            return np.array([np.array([]) for _ in range(len(points))])

        points_on_proc = np.array(points_on_proc, dtype=np.float64)
        cells_on_proc = np.array(cells_on_proc, dtype=np.int32)
        point_indices = np.array(point_indices, dtype=np.int32)
    else:
        # Use precomputed data
        if len(precomputed_data) == 2:
            # Backward compatibility with old precomputed_data format
            points_on_proc, cells_on_proc = precomputed_data
            point_indices = None
        else:
            # New format with point indices
            points_on_proc, cells_on_proc, point_indices = precomputed_data
            
        points = np.array(points, dtype=np.float64)  # Still need original points array for size
        if points.ndim == 1:
            points = points.reshape(1, -1)
        
        # If no points were found in precomputation
        if len(points_on_proc) == 0:
            return np.array([np.array([]) for _ in range(len(points))])

    # Evaluate function at these points
    u_values = u.eval(points_on_proc, cells_on_proc)

    # Initialize output array with NaNs for points not found
    result = np.full(len(points), np.nan, dtype=np.float64)

    # Fill in the results for points that were found
    if point_indices is not None:
        # Fast path - use precomputed indices
        for i, orig_idx in enumerate(point_indices):
            result[orig_idx] = u_values[i]
    else:
        # Slow path - use np.allclose to match points
        for i, point in enumerate(points_on_proc):
            # Find the index of this point in the original points array
            for j, orig_point in enumerate(points):
                if np.allclose(point, orig_point, rtol=1e-10, atol=1e-10):
                    result[j] = u_values[i]
                    break

    # Return as a 1D numpy array of length equal to the number of points
    return result

def precompute_eval_points_data(mesh, points, z_coordinate=None):
    """
    Precompute the cell collision data for eval_points to avoid redundant calculations.
    
    Args:
        mesh: DOLFINx mesh
        points: Array of points [(x, y), ...] or [(x, y, z), ...] where to evaluate the function
        z_coordinate: If provided, will be used as the z-coordinate for all points when points are 2D
                     (useful for toolpath evaluation at a specific height)
    
    Returns:
        Tuple of (points_on_proc, cells_on_proc, point_indices) to be passed to eval_points
        where point_indices maps back to the original point array indices
    """
    # Ensure points is a proper numpy array with correct shape
    points = np.array(points, dtype=np.float64)
    if points.ndim == 1:
        points = points.reshape(1, -1)
        
    # Handle 2D points by adding z-coordinate
    if points.shape[1] == 2:
        if z_coordinate is None:
            z_coordinate = BASEPLATE_THICKNESS+PART_HEIGHT-1e-6
            print(f"Warning: No z_coordinate provided for 2D points, using z={z_coordinate} as defined in config.py")
        
        # Create a new array with z-coordinate added
        points_3d = np.zeros((points.shape[0], 3), dtype=np.float64)
        points_3d[:, 0] = points[:, 0]  # x-coordinates
        points_3d[:, 1] = points[:, 1]  # y-coordinates
        points_3d[:, 2] = z_coordinate  # z-coordinate (same for all points)
        points = points_3d
    
    # Create bounding box tree - DOLFINx 0.9.0 syntax using bb_tree function
    bb_tree_obj = bb_tree(mesh, mesh.topology.dim)
    
    # Find candidate cells for each point
    # DOLFINx 0.9.0 expects points in shape (num_points, 3)
    potential_cells = compute_collisions_points(bb_tree_obj, points)
    
    # Find which cell actually contains each point
    cells = compute_colliding_cells(mesh, potential_cells, points)

    # Filter out points not found in the mesh
    points_on_proc = []
    cells_on_proc = []
    point_indices = []  # Track original indices
    
    for i in range(len(points)):
        cell_links = cells.links(i)
        if len(cell_links) > 0:
            points_on_proc.append(points[i])
            cells_on_proc.append(cell_links[0])  # Take the first containing cell
            point_indices.append(i)  # Store original index

    if len(points_on_proc) == 0:
        # No points found on this process
        return np.array([], dtype=np.float64), np.array([], dtype=np.int32), np.array([], dtype=np.int32)

    points_on_proc = np.array(points_on_proc, dtype=np.float64)
    cells_on_proc = np.array(cells_on_proc, dtype=np.int32)
    point_indices = np.array(point_indices, dtype=np.int32)
    
    return points_on_proc, cells_on_proc, point_indices

if __name__ == "__main__":
    from solver.config import PART_HEIGHT
    from dolfinx.io import gmshio
    from dolfinx.fem import Function, functionspace
    from dolfinx.mesh import create_unit_cube
    import numpy as np
    from mpi4py import MPI
    
    def test_eval_points():
        # Create a unit cube mesh
        mesh = create_unit_cube(MPI.COMM_WORLD, 10, 10, 10)
        V = functionspace(mesh, ("Lagrange", 1))
        u = Function(V)
        x = V.tabulate_dof_coordinates()

        u.x.array[:] = x[:, 0] + 2*x[:, 1] + 3*x[:, 2]
        test_points = np.array([
            [0.0, 0.0, 0.0],  # Should give 0 + 2*0 + 3*0 = 0
            [1.0, 0.0, 0.0],  # Should give 1 + 2*0 + 3*0 = 1
            [0.0, 1.0, 0.0],  # Should give 0 + 2*1 + 3*0 = 2
            [0.0, 0.0, 1.0],  # Should give 0 + 2*0 + 3*1 = 3
            [0.5, 0.5, 0.5],  # Should give 0.5 + 2*0.5 + 3*0.5 = 3.0
            [0.25, 0.75, 0.1] # Should give 0.25 + 2*0.75 + 3*0.1 = 2.05
        ])
        
        expected_values = np.array([0.0, 1.0, 2.0, 3.0, 3.0, 2.05])
        
        # Evaluate function at test points
        values = eval_points(mesh, test_points, u)
        
        # Test with 2D points (removing z-coordinate)
        mpi_print("\nTesting with 2D points (removing z-coordinate):")
        test_points_2d = test_points[:, 0:2]  # Remove z-coordinate
        mpi_print(f"2D points shape: {test_points_2d.shape}")
        
        # Evaluate at 2D points with z=0.5
        values_2d = eval_points(mesh, test_points_2d, u, z_coordinate=0.5)
        
        # Calculate expected values for z=0.5
        expected_values_2d = test_points_2d[:, 0] + 2*test_points_2d[:, 1] + 3*0.5
        
        # Check results
        tolerance = 1e-10
        for i, (expected, actual) in enumerate(zip(expected_values, values)):
            # With the new format, actual should always be an array
            if len(actual) == 0:
                mpi_print(f"  Point {test_points[i]}: ⚠️ Point not found on this process")
                continue
                
            actual_val = float(actual[0])  # Convert to float to avoid formatting issues
            error = abs(expected - actual_val)
            point = test_points[i]
            mpi_print(f"  Point {point}: expected={expected:.6f}, actual={actual_val:.6f}, error={error:.2e}")
            
            if error > tolerance:
                mpi_print(f"  ❌ FAILED: Error {error:.2e} > tolerance {tolerance}")
                return False
            else:
                mpi_print(f"  ✅ PASSED")
                
        # Check 2D points results
        mpi_print("\nChecking 2D points results (with z=0.5):")
        for i, (expected, actual) in enumerate(zip(expected_values_2d, values_2d)):
            # With the new format, actual should always be an array
            if len(actual) == 0:
                mpi_print(f"  Point {test_points_2d[i]} (z=0.5): ⚠️ Point not found on this process")
                continue
                
            actual_val = float(actual[0])  # Convert to float to avoid formatting issues
            error = abs(expected - actual_val)
            point_2d = test_points_2d[i]
            mpi_print(f"  Point {point_2d} (z=0.5): expected={expected:.6f}, actual={actual_val:.6f}, error={error:.2e}")
            
            if error > tolerance:
                mpi_print(f"  ❌ FAILED: Error {error:.2e} > tolerance {tolerance}")
                return False
            else:
                mpi_print(f"  ✅ PASSED")
        return True
    
    # Run the tests
    test_eval_points()

